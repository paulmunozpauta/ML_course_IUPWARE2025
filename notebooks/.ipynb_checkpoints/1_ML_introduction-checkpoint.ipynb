{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "    <img style=\"width: 30%;\" src=\"static/imgs/Logo_course.png\">\n",
    "    <p style=\"margin-top:10px;\">paul.andres.munoz@gmail.com<br>paul.munoz@vub.be</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "# Part 1. Introduction to Machine Learning\n",
    "\n",
    "In this session, we will:\n",
    "\n",
    "- Define what Machine Learning (ML) is.\n",
    "- Understand why we should use ML.\n",
    "- Explore applications of ML.\n",
    "- Learn about the types of ML algorithms.\n",
    "- Discuss ML challenges for hydrological and climate forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\n",
    "\n",
    "Machine Learning (ML) is the art and science of programming computers to learn from data.\n",
    "\n",
    "> [Arthur Samuel] ML is the field of study that gives computers the ability to learn without being explicitly programmed.\n",
    "\n",
    "Something more formal:\n",
    "\n",
    "> [Tom Mitchell] A computer program is said to learn from experience $E$ with respect to some task $T$ and some performance measure $P$, if its performance on $T$, as measured by $P$, improves with experience $E$.\n",
    "\n",
    "In hydrology:\n",
    "\n",
    "> Machine Learning (ML) is a branch of artificial intelligence that focuses on developing algorithms and statistical models that enable computers to learn and make predictions or decisions based on data.\n",
    "\n",
    "> ML is a subfield of artificial intelligence that develops algorithms and models capable of extracting patterns and making predictions from data, without being explicitly programmed for a specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Use Machine Learning?\n",
    "\n",
    "When we build systems that do not rely on machine learning, we generally follow these steps:\n",
    "\n",
    "1. Conceptualization (we create rules).\n",
    "2. Write an algorithm.\n",
    "3. If the algorithm works well, we implement it. If not, we return to step 1.\n",
    "\n",
    "However, if the problem is complex, we are likely to end up with a long list of rules that are difficult to follow and challenging to apply to other similar problems. A machine learning system would be much shorter, easier to maintain, and, in many cases, more accurate.\n",
    "\n",
    "With ML, we can simply train an algorithm on a large dataset and then inspect the algorithm's `feature importance` to better understand the relationship between the data and the problem. This process is known as data mining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of Machine Learning:\n",
    "\n",
    "ML has numerous applications, and here are some of the most notable in hydrology and climatology:\n",
    "\n",
    "- `Image Classification`: Typically performed using convolutional neural networks (CNNs).\n",
    "\n",
    "> In hydrology, this could be applied to classify satellite images to detect geographic features and weather conditions.\n",
    "\n",
    "- `Semantic Segmentation`: The algorithm is trained to classify each pixel in an image, such as detecting brain tumors.\n",
    "\n",
    "> In hydrology, it could be used to identify specific geographic features in satellite images.\n",
    "\n",
    "- `Natural Language Processing` (NLP): Specifically, text classification, which can be learned using RNNs, CNNs, or Transformers.\n",
    "\n",
    "> In weather forecasting, this could be used to analyze and classify weather reports and climate-related news.\n",
    "\n",
    "- Chatbots: Involve many NLP tasks, such as Natural Language Understanding (NLU) and Question Answering.\n",
    "\n",
    "> In hydrology, they could be used for monitoring systems and early warning applications.\n",
    "\n",
    "- `Forecasting Future Revenues`: A regression task that can be approached using various algorithms such as:\n",
    "  - Linear Regression\n",
    "  - Polynomial Regression\n",
    "  - Support Vector Machines (SVMs)\n",
    "  - Random Forests\n",
    "  - Neural Networks\n",
    "  \n",
    "> In hydrology, this could be applied to forecast river flow rates and water levels.\n",
    "\n",
    "- `Voice Recognition`: This task involves recognizing incoming audio signals using RNNs, CNNs, or Transformers.\n",
    "\n",
    "> In climate applications, it could be used to transcribe field observations.\n",
    "\n",
    "- `Fraud Detection`: Can be solved using supervised learning (classification) or unsupervised learning (anomaly detection).\n",
    "\n",
    "> In hydrological applications, it could detect anomalies in flood monitoring sensor data.\n",
    "\n",
    "- `Clustering`: Segmenting customers based on their purchases to design more effective targeted marketing campaigns.\n",
    "\n",
    "> In hydrology, this could be applied to segment geographic regions with similar weather patterns.\n",
    "\n",
    "- `Dimensionality Reduction`: Useful for visualizing high-dimensional data and cluster analysis. Algorithms like `PCA` or `T-SNE` can be used.\n",
    "\n",
    "> In climate applications, this could help visualize data from multiple climate variables.\n",
    "\n",
    "- `Recommendation Systems`: Inputting a customerâ€™s purchase sequence (for example) into a neural network to predict their next purchase.\n",
    "\n",
    "> In hydrology, this could be used to recommend flood mitigation measures based on historical patterns of flood events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Machine Learning Systems\n",
    "\n",
    "Machine learning (ML) algorithms can be classified based on the level of supervision they receive during training.\n",
    "\n",
    "There are 4 main types of ML algorithms:\n",
    "\n",
    "### Supervised Learning\n",
    "\n",
    "In supervised learning, the training dataset provided to the algorithm contains the desired targets/labels/predictions. Most supervised learning tasks fall into two categories: Classification and Regression.\n",
    "\n",
    "With classification, we aim to predict discrete values. Some examples include:\n",
    "\n",
    "- **Precipitation Event Classification**: Using classification to predict whether a precipitation event will be rain, a storm, or heavy rain. This is crucial for flood management and monitoring extreme weather events.\n",
    "- **Water Quality Classification**: Classification algorithms can help determine whether water is potable based on contaminant levels and the presence of harmful microorganisms.\n",
    "- **Flood Risk Classification**: Classification models can evaluate flood risk in specific areas based on variables like topography, river flow, and precipitation.\n",
    "- **Climate Type Classification**: Classification models can group geographic areas based on their climate patterns, such as tropical, subtropical, or arid climates.\n",
    "\n",
    "On the other hand, regression deals with continuous target values. Examples include:\n",
    "\n",
    "- **River Flow Prediction**: Regression is used to predict river flow based on historical precipitation, temperature, and geographic characteristics.\n",
    "- **Groundwater Level Modeling**: Regression models can predict groundwater levels based on recharge, extraction, and other hydrological variables.\n",
    "- **Evapotranspiration Prediction**: Regression is used to predict the amount of water that evaporates and transpires based on solar radiation, temperature, and humidity.\n",
    "- **Temperature Regression**: Regression is used to predict daily maximum and minimum temperatures based on historical weather data, such as solar radiation, altitude, and latitude.\n",
    "- **Precipitation Prediction**: Regression algorithms can predict the amount of precipitation in a region based on prior climate data, such as wind patterns and sea temperatures.\n",
    "\n",
    "Some regression-based models are also used for classification, such as `Logistic Regression`, which outputs a probability $\\in [0,1]$. Popular supervised learning algorithms include:\n",
    "\n",
    "- K-Nearest Neighbors\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "- Decision Trees and Random Forests\n",
    "- Neural Networks\n",
    "- Naive Bayes\n",
    "\n",
    "### Unsupervised Learning\n",
    "\n",
    "In unsupervised learning, the data has no labels, and the system tries to learn without a teacher by finding internal structure within the dataset.\n",
    "\n",
    "Some unsupervised learning algorithms include:\n",
    "\n",
    "- **Clustering**:\n",
    "  - **K-Means**:\n",
    "    > K-Means can group geographic regions based on similar climate patterns. This can help identify areas with comparable climates and facilitate agricultural planning and water resource management.\n",
    "  - **DBSCAN**:\n",
    "    > DBSCAN can identify areas of high concentration of heavy rainfall events in a dataset of precipitation records, which is crucial for identifying flood-prone zones.\n",
    "  - **Hierarchical Clustering**:\n",
    "    > Hierarchical clustering organizes geographic regions into a tree of clusters based on climate similarities. This helps classify and understand climate patterns at different spatial scales.\n",
    "\n",
    "- **Anomaly Detection**:\n",
    "  - **One-Class SVM**:\n",
    "    > One-Class SVM detects anomalies in river water level time series, identifying unusual events like flash floods or severe droughts.\n",
    "  - **Isolation Forest**:\n",
    "    > Isolation Forest identifies outliers in climate datasets, which could indicate extreme weather events, such as exceptional heatwaves or extreme cold events.\n",
    "  - **Autoencoders**:\n",
    "    > Autoencoders detect anomalous patterns in water quality records, identifying unusual changes in water composition that could signal contamination issues.\n",
    "\n",
    "- **Dimensionality Reduction**: The goal is to compress data without losing too much information (e.g., combining highly correlated features).\n",
    "  - **Principal Component Analysis (PCA)**:\n",
    "    > PCA is commonly used to reduce the dimensionality of multivariate climate data, simplifying the analysis of complex climate patterns and visualizing data.\n",
    "  - **Kernel PCA**:\n",
    "    > Kernel PCA reduces the dimensionality of climate data using nonlinear kernel functions, useful for highly nonlinear climate datasets like global temperature patterns.\n",
    "  - **T-SNE**:\n",
    "    > T-SNE is used to visualize river flow time series data in a two-dimensional space, making it easier to identify temporal patterns and trends in hydrological data.\n",
    "\n",
    "- **Association Rule Learning**:\n",
    "  - **Apriori**:\n",
    "    > Apriori can uncover interesting associations between climate variables, such as the relationship between temperature and relative humidity across different regions.\n",
    "  - **Eclat**:\n",
    "    > Eclat identifies relationships in hydrogeological data, such as the association between soil permeability and aquifer recharge in specific areas.\n",
    "\n",
    "### Semi-Supervised Learning\n",
    "\n",
    "In semi-supervised learning, we have partially labeled data. The goal is to use unlabeled data around the labeled data to help solve the task. Most semi-supervised learning algorithms combine supervised and unsupervised approaches.\n",
    "\n",
    "For example, in a flood prediction project for a specific watershed:\n",
    "- **Labeled Data**: Past flood and non-flood events labeled based on water level records at monitoring stations.\n",
    "- **Unlabeled Data**: Most collected data remains unlabeled and corresponds to conditions where flood occurrence is unknown.\n",
    "- **Supervised Learning Model**: Initially trains on labeled data to predict floods, providing reasonable but limited performance due to insufficient labeled data.\n",
    "- **Incorporating Unlabeled Data**: Unlabeled data is integrated into the training process, allowing the model to learn additional patterns and trends in pre-flood conditions.\n",
    "- **Improved Predictions**: The model becomes more accurate in flood prediction, even under previously unseen conditions.\n",
    "- **Real-Time Flood Alerts**: The improved model powers a real-time flood early warning system, delivering alerts based on continuous monitoring data, even when new data is unlabeled.\n",
    "\n",
    "### Reinforcement Learning\n",
    "\n",
    "An agent observes the environment, selects an action, receives a reward, and updates its policy. This approach is used in applications like games and robot control.\n",
    "\n",
    "Examples:\n",
    "- **Reservoir Management**: A reinforcement learning agent observes precipitation and temperature conditions and selects actions (e.g., release or retain water). The reward is based on water distribution efficiency and flood prevention.\n",
    "- **Storm Prediction**: In climatology, a reinforcement learning agent observes real-time weather data and predicts storm intensity and impact. Rewards are linked to prediction accuracy.\n",
    "- **Flood Control**: In hydrology, reinforcement learning agents operate gates and dams to manage river flow and prevent flooding, receiving rewards for maintaining safe water levels.\n",
    "- **Renewable Energy Optimization**: A reinforcement learning agent manages wind or solar energy production based on weather conditions, maximizing efficiency and profitability.\n",
    "\n",
    "### Batch Learning vs. Online Learning\n",
    "\n",
    "- **Batch Learning**: Models are trained on all available data at once, then deployed to make predictions without being updated with new data. Suitable for static historical datasets.\n",
    "\n",
    "Example:\n",
    "> Historical water levels and precipitation data are used to train a flood prediction model once. The model is deployed for real-time predictions but cannot update with new data.\n",
    "\n",
    "- **Online Learning**: Models are trained incrementally as data arrives, adapting to new information over time. Suitable for systems receiving continuous data streams.\n",
    "\n",
    "Example:\n",
    "> A weather forecasting model continuously updates its predictions with real-time temperature, humidity, and pressure measurements. This ensures forecasts adapt to changing weather conditions.\n",
    "\n",
    "### Instance-Based vs. Model-Based Learning\n",
    "\n",
    "- **Instance-Based Learning**: Predictions are made by comparing new data points to historical data based on similarity.\n",
    "\n",
    "Example:\n",
    "> For water quality monitoring, new measurements are compared to historical data from similar conditions (e.g., geography, climate) to predict quality.\n",
    "\n",
    "- **Model-Based Learning**: Predictions are made using a trained model that captures complex relationships within the data.\n",
    "\n",
    "Example:\n",
    "> A climate prediction model uses variables like temperature, humidity, and pressure to forecast future weather patterns, relying on learned relationships rather than direct comparisons to historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets start with the basics\n",
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import sklearn.linear_model\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read runoff and precipitation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = os.getcwd()\n",
    "print(root_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(root_directory, \"data/Hourly_runoff.xlsx\")\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hourly_runoff = pd.read_excel(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hourly_runoff.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hourly_runoff['Date'] = Hourly_runoff.Date.apply(lambda x: pd.to_datetime(x,dayfirst=False))\n",
    "Hourly_runoff.set_index(Hourly_runoff['Date'],inplace=True)\n",
    "Hourly_runoff = Hourly_runoff.drop(columns=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hourly_runoff['Runoff (m3/s)'] = pd.to_numeric(Hourly_runoff['Runoff (m3/s)'], errors='coerce')\n",
    "Hourly_runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hourly_runoff.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "Hourly_runoff.plot(ax=ax)\n",
    "plt.ylabel('Runoff ($m^3/s$)')\n",
    "plt.legend().set_visible(False)\n",
    "os.makedirs(os.path.join(root_directory, \"figures\"), exist_ok=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(root_directory+'/figures', 'Runoff_plot.jpg'), format='jpg', dpi =300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(root_directory, \"data/Hourly_precipitation.csv\")\n",
    "print(data_path)\n",
    "Hourly_pcp = pd.read_csv(data_path)\n",
    "Hourly_pcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hourly_pcp = Hourly_pcp.rename(columns={'Date_yy/mm/dd_hh:mm:ss': 'Date'})\n",
    "Hourly_pcp['Date'] = Hourly_pcp.Date.apply(lambda x: pd.to_datetime(x,dayfirst=False))\n",
    "Hourly_pcp = Hourly_pcp.drop(columns=['Cumulated_precipitation_Texas_mm'])\n",
    "Hourly_pcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hourly_pcp.set_index(Hourly_pcp['Date'],inplace=True)\n",
    "Hourly_pcp = Hourly_pcp.drop(columns=['Date'])\n",
    "Hourly_pcp['tip_corrected_mm'] = pd.to_numeric(Hourly_pcp['tip_corrected_mm'], errors='coerce')\n",
    "Hourly_pcp = Hourly_pcp.sort_index()\n",
    "Hourly_pcp.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "Hourly_pcp.plot(ax=ax)\n",
    "plt.ylabel('Hourly precipitation ($mm$)')\n",
    "plt.legend().set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(root_directory+'/figures', 'Precipitation_plot.jpg'), format='jpg', dpi =300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "Hourly_pcp.loc['2020'].cumsum().plot(ax=ax)\n",
    "plt.ylabel('Accumulated precipitation ($mm$)')\n",
    "plt.legend().set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(root_directory+'/figures', 'Cumulated_precipitation.jpg'), format='jpg', dpi =300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hourly_runoff.index = Hourly_runoff.index.round(freq='H')\n",
    "Hourly_pcp.index = Hourly_pcp.index.round(freq='H')\n",
    "Hourly_data = pd.concat([Hourly_runoff, Hourly_pcp],axis=1, join='outer')\n",
    "Hourly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_analysis='2018'\n",
    "end_analysis='2020'\n",
    "fig,ax = plt.subplots()\n",
    "plt.ylim(ymax=300)\n",
    "ax2 = ax.twinx()\n",
    "plt.ylim(ymax=50)\n",
    "ax.plot(Hourly_data['Runoff (m3/s)'][start_analysis:end_analysis],color='red',label='Precipitation')\n",
    "ax2.plot(Hourly_data['tip_corrected_mm'][start_analysis:end_analysis],color='blue',label='Runoff')\n",
    "plt.gca().invert_yaxis()\n",
    "ax.legend(loc=(0.05,0.55))\n",
    "ax2.legend(loc=(0.4,0.55))\n",
    "ax.set_ylabel('Hourly runoff ($m^3/s$)')\n",
    "ax2.set_ylabel('Hourly precipitation (mm)')\n",
    "ax2.set_xlabel('Date')\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(root_directory+'/figures', 'Precipitation_vs_runoff.jpg'), format='jpg', dpi =300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a Linear Model\n",
    "Hourly_data = Hourly_data.dropna()\n",
    "X = Hourly_data['tip_corrected_mm'][Hourly_data['tip_corrected_mm']>0].to_numpy()\n",
    "X_reshaped = X.reshape(-1, 1)\n",
    "Y = Hourly_data['Runoff (m3/s)'][Hourly_data['tip_corrected_mm']>0].to_numpy()\n",
    "Y_reshaped = Y.reshape(-1, 1)\n",
    "model = sklearn.linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "model.fit(X_reshaped,Y_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = [[20]]  \n",
    "print(model.predict(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's visualize our model, because it's a linear one, we can plot it using two points\n",
    "X = [[0], [20]]\n",
    "y_hat = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Data\n",
    "Hourly_data[Hourly_data['tip_corrected_mm']>0].plot(kind='scatter', x='tip_corrected_mm', y='Runoff (m3/s)', xlim=(0, 20), ylim=(0,200))\n",
    "plt.plot(X, y_hat, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is a linera model sufficient to describe precipitation-runoff relations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, we follow these steps to implement a machine learning algorithm:\n",
    "\n",
    "1. Study the data and process the information.\n",
    "2. Select the model.\n",
    "3. Train the model.\n",
    "4. Make inferences using the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Challenges of ML for Streamflow and Climate Forecasting\n",
    "\n",
    "The two main challenges are:\n",
    "\n",
    "1. Poor data quality.\n",
    "2. Selecting an inappropriate learning algorithm.\n",
    "\n",
    "#### Data\n",
    "\n",
    "- It has been demonstrated that many algorithms, from the simplest to the most complex, perform relatively similarly when provided with sufficient data.\n",
    "- Therefore, greater effort is suggested in ML algorithm development or **feature engineering**.\n",
    "- The training dataset may not be representative of the overall data distribution. This creates problems for effective generalization. For example:\n",
    "  - If the training dataset is too small, it will suffer from sampling noise.\n",
    "  - Even large samples can be unrepresentative if the sampling method is flawed, a problem known as **sampling bias**.\n",
    "- Hydrological and climate data can vary significantly over time and space. Selecting the appropriate scale for modeling is crucial.\n",
    "- Low-quality data is also a major challenge. Accurate data on precipitation, temperature, streamflow, and other parameters is essential. Inaccurate data can lead to incorrect results and poor decisions (especially if the measurements of the target variable are unreliable!).\n",
    "- Training data filled with outliers, errors, and noise makes it harder for the algorithm to detect underlying patterns, resulting in a poor model. Meteorological and hydrological station records may also have missing values or measurement errors that must be addressed effectively.\n",
    "- Additionally, datasets may contain irrelevant features (predictors). The system will only learn effectively if the data includes many relevant features and few irrelevant ones. A critical success factor for ML projects is **feature engineering**, which involves creating features that result in a quality model.\n",
    "\n",
    "#### Feature Selection and Engineering\n",
    "\n",
    "Feature selection and engineering are particularly important in this context:\n",
    "\n",
    "- **Climate and Hydrology Relevance**: Identifying the most relevant climatic and hydrological features is crucial for correctly modeling phenomena such as precipitation, river flow, and climate change.\n",
    "- **Inclusion of Specific Variables**: Variables like altitude, soil type, vegetation, and topographic characteristics can be fundamental in hydrology and climatology.\n",
    "\n",
    "#### Overfitting\n",
    "\n",
    "Overfitting occurs when the ML model performs well on training data but fails to generalize to test data.\n",
    "\n",
    "- Complex models, such as deep neural networks, tend to memorize the noise in the training data or even the data samples themselves if the dataset is small.\n",
    "- To mitigate overfitting:\n",
    "  - Select a model with fewer weights/parameters to limit predictive capacity to the strongest patterns.\n",
    "  - Collect more training data.\n",
    "  - Reduce noise in the training data by correcting errors and removing outliers.\n",
    "\n",
    "Mitigating overfitting is referred to as **regularization**. For example:\n",
    "- A linear regression model ($f(x) = ax + b$) has two degrees of freedom (2 parameters).\n",
    "- Restricting the flexibility of one parameter within a range reduces the degrees of freedom to 1â€“2, striking a balance between simplicity and pattern detection.\n",
    "\n",
    "Regularization is controlled using model hyperparameters, which define how the model learns. Specific considerations for streamflow and climate modeling include:\n",
    "\n",
    "- **Overfitting in Time Series**: Common due to the complexity of climate and hydrological patterns. Pay attention to model selection and regularization techniques.\n",
    "- **Climate and Hydrological Uncertainty**: Models must capture and quantify inherent uncertainty in these phenomena.\n",
    "\n",
    "#### Underfitting\n",
    "\n",
    "Underfitting is the opposite of overfitting. It occurs when the model is too simple to capture the underlying structure of the training data. Solutions include:\n",
    "- Selecting a more powerful model with more parameters.\n",
    "- Feeding better features to the algorithm (feature engineering).\n",
    "- Reducing restrictions on the model (lower regularization).\n",
    "\n",
    "#### Knowledge Transfer\n",
    "\n",
    "Knowledge transfer between regions or temporal scales is crucial in hydrology and climatology:\n",
    "\n",
    "- **Climate Model Transfer**: Adapting climate models trained in one region to another may require advanced techniques for adjustment and validation.\n",
    "- **Climate Extrapolation**: Predicting future climate behavior based on historical data is a significant challenge requiring robust modeling techniques.\n",
    "\n",
    "#### Climate Change Adaptation\n",
    "\n",
    "In the context of climate change, it is critical to:\n",
    "\n",
    "- **Incorporate Future Climate Scenarios**: Models must integrate climate projections to provide accurate predictions in changing conditions.\n",
    "- **Evaluate Hydrological Impacts**: Models should assess potential changes in precipitation and streamflow patterns and their effects on hydrological systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Validation\n",
    "\n",
    "Testing and validation of ML models are critical to ensuring their accuracy and reliability in predicting climatic and hydrological phenomena.\n",
    "\n",
    "We can evaluate our model by splitting the data into two sets: a **training set** and a **test set**. The main focus is on the **generalization error**, or out-of-sample error, which reflects the model's performance in a production environment.\n",
    "\n",
    "If the training error is low but the test error is high, this indicates that the model is overfitting. A common practice is to use **70%** of the data for training and the remaining **30%** for testing, although the exact proportion depends on the size of the dataset. For larger datasets, a smaller percentage can be used for testing. What about hydrology?\n",
    "\n",
    "When regularization parameters are tuned using the test set, the model risks overfitting to this set. To avoid this, a separate **validation set** is required for hyperparameter tuning. After tuning, the model is trained on the full training set (including the validation set) and evaluated on the test set.\n",
    "\n",
    "A simple yet computationally expensive solution for reserving a large validation set is to perform repeated cross-validation. However, this requires training the model N times. Both the validation and test sets must be as representative as possible of the data used in production. Is **K-fold cross-validation** a solution?\n",
    "\n",
    "---\n",
    "\n",
    "### Key Considerations\n",
    "\n",
    "#### Data Splitting\n",
    "\n",
    "For hydrology and climatology models, it is essential to carefully divide data into training and test sets. **Representative sets** must be selected, considering the wide variability in climatic and hydrological patterns across locations and time periods. Ensuring the training and test sets reflect real-world conditions for the region of interest is critical.\n",
    "\n",
    "#### Cross-Validation\n",
    "\n",
    "When data is limited and valuable, cross-validation provides a more robust evaluation of model performance. It helps address different conditions and locations, particularly in datasets with high spatial and temporal variability.\n",
    "\n",
    "#### Noise and Pattern Considerations\n",
    "\n",
    "Climatic and hydrological data are often affected by noise from seasonal fluctuations or extreme events. Models must capture relevant patterns while ignoring noise. Can signal decomposition techniques help?\n",
    "\n",
    "#### Model Assumptions\n",
    "\n",
    "Models are often based on specific assumptions about the relationships between variables. For example, linear regression assumes a linear relationship, which may not always reflect the complexity of climatic and hydrological phenomena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
