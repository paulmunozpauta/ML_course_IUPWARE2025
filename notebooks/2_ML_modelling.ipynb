{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf /content/ML_course_IUPWARE2025"
      ],
      "metadata": {
        "id": "PWYheXgMaUc9"
      },
      "id": "PWYheXgMaUc9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IUPWARE 2025 refresher course: Satellite precipitation & Machine Learning hydrological modelling"
      ],
      "metadata": {
        "id": "y6CoUb5OXNnT"
      },
      "id": "y6CoUb5OXNnT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"text-align:center;\">\n",
        "    <img src=\"https://github.com/paulmunozpauta//ML_course_IUPWARE2025/blob/main/notebooks/static/imgs/Logo_course.png?raw=1\" width=\"300\">\n",
        "    <p style=\"margin-top:10px;\">paul.munoz@vub.be</p>\n",
        "    <p>Find me on my <a href=\\\"https://paulmunozpauta.github.io/paulmunozpauta/index.html\\\" target=\\\"_blank\\\">personal website</a></p>\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "cY8Bcd1_ZD8g"
      },
      "id": "cY8Bcd1_ZD8g"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before starting, follow this four steps to run the notebook on Google Colab"
      ],
      "metadata": {
        "id": "VU87K-KEi4ko"
      },
      "id": "VU87K-KEi4ko"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1. Clone GitHub repository with notebooks and data for the course\n"
      ],
      "metadata": {
        "id": "xwSgGGyUjFr0"
      },
      "id": "xwSgGGyUjFr0"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -- https://github.com/paulmunozpauta/ML_course_IUPWARE2025.git"
      ],
      "metadata": {
        "id": "5-sQWZ2Li4Un"
      },
      "id": "5-sQWZ2Li4Un",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Let's move to the cloned folder\n",
        "\n"
      ],
      "metadata": {
        "id": "NWXPzpZhjJSZ"
      },
      "id": "NWXPzpZhjJSZ"
    },
    {
      "cell_type": "code",
      "source": [
        "ls\n"
      ],
      "metadata": {
        "id": "ZoxJZnBii4Rk"
      },
      "id": "ZoxJZnBii4Rk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ML_course_IUPWARE2025\n"
      ],
      "metadata": {
        "id": "LsGV4Z0ii4O3"
      },
      "id": "LsGV4Z0ii4O3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "v3McxR3di4Ml"
      },
      "id": "v3McxR3di4Ml",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Set-up environment for running course's code\n"
      ],
      "metadata": {
        "id": "6Equu3RsjN7Q"
      },
      "id": "6Equu3RsjN7Q"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Poetry\n",
        "!pip install poetry\n",
        "# Disable virtual environment creation (needed for Colab)\n",
        "!poetry config virtualenvs.create false"
      ],
      "metadata": {
        "id": "5AexfO4Wi4KA"
      },
      "id": "5AexfO4Wi4KA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If session restarts, repeat Steps 2-3.\n",
        "If not, move to Step 4\n"
      ],
      "metadata": {
        "id": "ApaBIJBGCitE"
      },
      "id": "ApaBIJBGCitE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Install required packages for the course\n"
      ],
      "metadata": {
        "id": "yyOc52YFjShA"
      },
      "id": "yyOc52YFjShA"
    },
    {
      "cell_type": "code",
      "source": [
        "!poetry install --no-root\n"
      ],
      "metadata": {
        "id": "ynP1G37Ui4HZ"
      },
      "id": "ynP1G37Ui4HZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's start wit the hands-on course\n",
        "\n"
      ],
      "metadata": {
        "id": "KwOYtFTsja8k"
      },
      "id": "KwOYtFTsja8k"
    },
    {
      "cell_type": "markdown",
      "id": "0e1ce37e",
      "metadata": {
        "id": "0e1ce37e"
      },
      "source": [
        "# Part 2: Development of Machine Learning hydrological models\n",
        "\n",
        "In this session, we will:\n",
        "   - Develop forecasting models for the mountain catchment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce59d2de",
      "metadata": {
        "id": "ce59d2de"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7a8a96e",
      "metadata": {
        "id": "c7a8a96e"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.dates as dates\n",
        "import os\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from copy import deepcopy\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import itertools\n",
        "import random\n",
        "\n",
        "def lagged_dataset(arr, num_steps, additional_arr, new_num_steps):\n",
        "    num_columns = arr.shape[1]\n",
        "    modified_rows = []\n",
        "    excluded_data = []\n",
        "    for i in range(num_steps, arr.shape[0]):\n",
        "        prev_rows = arr[i - num_steps:i]\n",
        "        current_row = arr[i]\n",
        "        new_row = np.concatenate((prev_rows.flatten(), current_row))\n",
        "        modified_rows.append(new_row)\n",
        "    result_array = np.array(modified_rows)\n",
        "    # Slicing the result_array to match the number of rows in modified_additional_arr\n",
        "    if result_array.shape[0] > additional_arr.shape[0]:\n",
        "        result_array = result_array[result_array.shape[0] - additional_arr.shape[0]:]\n",
        "\n",
        "    modified_rows = []\n",
        "    for i in range(new_num_steps, additional_arr.shape[0]):\n",
        "        prev_rows = additional_arr[i - new_num_steps:i]\n",
        "        current_row = additional_arr[i]\n",
        "        excluded_data.append(current_row[-1])  # Store excluded data\n",
        "        new_row = np.concatenate((prev_rows.flatten(), current_row[:-1]))  # Exclude last column\n",
        "        modified_rows.append(new_row)\n",
        "\n",
        "    modified_additional_arr = np.array(modified_rows)\n",
        "\n",
        "    # Adjust dimensions by removing rows from result_array or modified_additional_arr\n",
        "    min_rows = min(result_array.shape[0], modified_additional_arr.shape[0])\n",
        "    result_array = result_array[-min_rows:]\n",
        "    modified_additional_arr = modified_additional_arr[-min_rows:]\n",
        "    excluded_data = np.array(excluded_data)[-min_rows:]\n",
        "\n",
        "    # Concatenate result_array and modified_additional_arr\n",
        "    final_result = np.concatenate((result_array, modified_additional_arr), axis=1)\n",
        "\n",
        "    return final_result, np.array(excluded_data)[:, None]\n",
        "\n",
        "def lagged_dataset_pron(arr, num_steps, additional_arr, new_num_steps, lead_time):\n",
        "    num_columns = arr.shape[1]\n",
        "    modified_rows = []\n",
        "    excluded_data = []\n",
        "\n",
        "    for i in range(num_steps, arr.shape[0]):\n",
        "        prev_rows = arr[i - num_steps:i]\n",
        "        current_row = arr[i]\n",
        "        new_row = np.concatenate((prev_rows.flatten(), current_row))\n",
        "        modified_rows.append(new_row)\n",
        "\n",
        "    result_array = np.array(modified_rows)\n",
        "\n",
        "    # Slicing the result_array to match the number of rows in modified_additional_arr\n",
        "    if result_array.shape[0] > additional_arr.shape[0]:\n",
        "        result_array = result_array[result_array.shape[0] - additional_arr.shape[0]:]\n",
        "\n",
        "    modified_rows = []\n",
        "    for i in range(new_num_steps, additional_arr.shape[0]):\n",
        "        prev_rows = additional_arr[i - new_num_steps:i]\n",
        "        current_row = additional_arr[i]\n",
        "        excluded_data.append(current_row[-1])  # Store excluded data\n",
        "        new_row = np.concatenate((prev_rows.flatten(), current_row))  # Include last column\n",
        "        modified_rows.append(new_row)\n",
        "\n",
        "    modified_additional_arr = np.array(modified_rows)\n",
        "\n",
        "    # Adjust dimensions by removing rows from result_array or modified_additional_arr\n",
        "    min_rows = min(result_array.shape[0], modified_additional_arr.shape[0])\n",
        "    result_array = result_array[-min_rows:]\n",
        "    modified_additional_arr = modified_additional_arr[-min_rows:]\n",
        "    excluded_data = np.array(excluded_data)[-min_rows:]\n",
        "\n",
        "    # Shift excluded_data by lead_time\n",
        "    excluded_data = excluded_data[lead_time:]\n",
        "\n",
        "    # Concatenate result_array and modified_additional_arr\n",
        "    final_result = np.concatenate((result_array, modified_additional_arr), axis=1)\n",
        "\n",
        "    # Resize final_result and excluded_data to have the same number of rows\n",
        "    min_rows = min(final_result.shape[0], excluded_data.shape[0])\n",
        "    final_result = final_result[:min_rows]\n",
        "    excluded_data = excluded_data[:min_rows]\n",
        "\n",
        "    return final_result, np.array(excluded_data)[:, None]\n",
        "\n",
        "\n",
        "def calculate_hydro_metrics(simulations, evaluation):\n",
        "    sim_mean = np.mean(simulations, axis=0, dtype=np.float64)\n",
        "    obs_mean = np.mean(evaluation, dtype=np.float64)\n",
        "\n",
        "    r_num = np.sum((simulations - sim_mean) * (evaluation - obs_mean),\n",
        "                   axis=0, dtype=np.float64)\n",
        "    r_den = np.sqrt(np.sum((simulations - sim_mean) ** 2,\n",
        "                           axis=0, dtype=np.float64)\n",
        "                    * np.sum((evaluation - obs_mean) ** 2,\n",
        "                             dtype=np.float64))\n",
        "    r = r_num / r_den\n",
        "    # calculate error in spread of flow alpha\n",
        "    alpha = np.std(simulations, axis=0) / np.std(evaluation, dtype=np.float64)\n",
        "    # calculate error in volume beta (bias of mean discharge)\n",
        "    beta = (np.sum(simulations, axis=0, dtype=np.float64)\n",
        "            / np.sum(evaluation, dtype=np.float64))\n",
        "    # calculate the Kling-Gupta Efficiency KGE\n",
        "    kge = 1 - np.sqrt((r - 1) ** 2 + (alpha - 1) ** 2 + (beta - 1) ** 2)\n",
        "    rmse = np.sqrt(np.mean((evaluation - simulations) ** 2,\n",
        "                            axis=0, dtype=np.float64))\n",
        "    pbias = (100 * np.sum(evaluation - simulations, axis=0, dtype=np.float64)\n",
        "              / np.sum(evaluation))\n",
        "    r2 = 1 - (np.sum((evaluation - simulations)**2) / np.sum((evaluation - np.mean(evaluation))**2))\n",
        "    return kge, rmse, pbias, r2\n",
        "np.random.seed(22)\n",
        "random.seed(22)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "785a3064",
      "metadata": {
        "id": "785a3064"
      },
      "source": [
        "## Select project folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85381a55",
      "metadata": {
        "id": "85381a55"
      },
      "outputs": [],
      "source": [
        "folder = os.getcwd()+'/notebooks/data/'\n",
        "folder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b745e22b",
      "metadata": {
        "id": "b745e22b"
      },
      "source": [
        "## Import precipitation data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9f65ceb",
      "metadata": {
        "id": "a9f65ceb"
      },
      "source": [
        "### Satellite precipitation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85e409de",
      "metadata": {
        "id": "85e409de"
      },
      "source": [
        "Read data from the mountain catchment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a895238",
      "metadata": {
        "scrolled": true,
        "id": "9a895238"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import satellite precipitation data\n",
        "precipitation_satellite = pd.read_csv(folder + 'PERSIANN-CCS_UTC_daily_catchment_1.csv', sep=',')\n",
        "# Rename columns\n",
        "precipitation_satellite.rename(columns={'Unnamed: 0': 'Date'}, inplace=True)\n",
        "# Convert 'Date' column to datetime format (without unnecessary dayfirst=True)\n",
        "precipitation_satellite['Date'] = pd.to_datetime(precipitation_satellite['Date'], format='%Y-%m-%d')\n",
        "# Set 'Date' as the index\n",
        "precipitation_satellite.set_index('Date', inplace=True)\n",
        "# Print first rows to verify\n",
        "print(precipitation_satellite.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4be9d91",
      "metadata": {
        "id": "e4be9d91"
      },
      "outputs": [],
      "source": [
        "precipitation_satellite"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de1f5926",
      "metadata": {
        "id": "de1f5926"
      },
      "source": [
        "Calculate annual precipitation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf220da3",
      "metadata": {
        "scrolled": true,
        "id": "cf220da3"
      },
      "outputs": [],
      "source": [
        "# Resample annual precipitation data\n",
        "data_annual = precipitation_satellite.resample('YE', label='right', closed='right').sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "181311c8",
      "metadata": {
        "id": "181311c8"
      },
      "source": [
        "Plot average annual precipitation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d255b712",
      "metadata": {
        "id": "d255b712"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "data_annual.plot(kind='bar', ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_satellite (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd41dc08",
      "metadata": {
        "id": "dd41dc08"
      },
      "source": [
        "Calculate average annual precipitation for all pixels in the basin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "423c5bf9",
      "metadata": {
        "scrolled": true,
        "id": "423c5bf9"
      },
      "outputs": [],
      "source": [
        "data_annual_average =  data_annual.mean(axis=1)\n",
        "data_annual_average"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "268a4c9d",
      "metadata": {
        "id": "268a4c9d"
      },
      "source": [
        "Plot the average precipitation (all pixels)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77108f4c",
      "metadata": {
        "id": "77108f4c"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "data_annual_average.plot(kind='bar', ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_satellite (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5566822",
      "metadata": {
        "id": "f5566822"
      },
      "source": [
        "Calculate the average annual precipitation in the basin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "158532d0",
      "metadata": {
        "id": "158532d0"
      },
      "outputs": [],
      "source": [
        "data_annual_average.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a04b0b3",
      "metadata": {
        "id": "1a04b0b3"
      },
      "source": [
        "Calculate monthly precipitation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afdcc548",
      "metadata": {
        "id": "afdcc548"
      },
      "outputs": [],
      "source": [
        "data_monthly = precipitation_satellite.resample('M',label='right',closed='right').sum()\n",
        "data_monthly"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc05667b",
      "metadata": {
        "id": "fc05667b"
      },
      "source": [
        "Calculate monthly precipitation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "599bc0ab",
      "metadata": {
        "id": "599bc0ab"
      },
      "outputs": [],
      "source": [
        "data_monthly_mean_pixels =  data_monthly.mean(axis=1)\n",
        "data_monthly_mean_pixels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc48a367",
      "metadata": {
        "id": "fc48a367"
      },
      "source": [
        "Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59682b5c",
      "metadata": {
        "id": "59682b5c"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(40,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "data_monthly_mean_pixels.plot(kind='bar', ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_satellite (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4698599c",
      "metadata": {
        "id": "4698599c"
      },
      "source": [
        "Calculate average monthly precipitation (average of all pixels in the basin)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abe79312",
      "metadata": {
        "id": "abe79312"
      },
      "outputs": [],
      "source": [
        "data_monthly_mean= data_monthly_mean_pixels.groupby(data_monthly_mean_pixels.index.month).mean()\n",
        "data_monthly_mean"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9edc31a",
      "metadata": {
        "id": "d9edc31a"
      },
      "source": [
        "Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71489e7f",
      "metadata": {
        "id": "71489e7f"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "data_monthly_mean.plot(kind='bar', ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_satellite (mm)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "663db72f",
      "metadata": {
        "id": "663db72f"
      },
      "source": [
        "### Import in-situ precipitation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f74626f",
      "metadata": {
        "id": "9f74626f"
      },
      "source": [
        "Let's use three rain gauges installed within the catchment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "358feba1",
      "metadata": {
        "id": "358feba1"
      },
      "source": [
        "#### For rain gauge 1\n",
        "Import and preprocess the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed797176",
      "metadata": {
        "id": "ed797176"
      },
      "outputs": [],
      "source": [
        "folder_pcp_1 = folder+'Rain_gauge_1/'\n",
        "df_pcp_1= pd.read_table(folder_pcp_1+'Rain_gauge_1.csv', sep=',')\n",
        "df_pcp_1.rename(columns={'Texas_tip_corrected_mm':'Pluviómetro_1'},inplace=True)\n",
        "df_pcp_1.columns\n",
        "df_pcp_1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24af0132",
      "metadata": {
        "id": "24af0132"
      },
      "source": [
        "Operations to organize the information into a manageable dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c5cf6d5",
      "metadata": {
        "id": "9c5cf6d5"
      },
      "outputs": [],
      "source": [
        "# Rename the column 'Date_yy/mm/dd_hh:mm:ss' to 'Date'\n",
        "df_pcp_1.rename(columns={'Date_yy/mm/dd_hh:mm:ss': 'Date'}, inplace=True)\n",
        "# Convert the 'Date' column to datetime format\n",
        "df_pcp_1['Date'] = df_pcp_1['Date'].apply(lambda x: pd.to_datetime(x, dayfirst=True))\n",
        "# Set the 'Date' column as the index\n",
        "df_pcp_1.set_index('Date', inplace=True)\n",
        "df_pcp_1 = df_pcp_1[~df_pcp_1.index.duplicated(keep='first')]\n",
        "\n",
        "df_pcp_1 = df_pcp_1.sort_index()\n",
        "\n",
        "df_pcp_1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d5c639a",
      "metadata": {
        "id": "6d5c639a"
      },
      "source": [
        "Plot the year 2020 from the imported precipitation series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b21deec",
      "metadata": {
        "id": "6b21deec"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "df_pcp_1.loc['2020'].plot(ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_in situ (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1f9ff66",
      "metadata": {
        "id": "f1f9ff66"
      },
      "source": [
        "Plot the accumulated precipitation for 2020 from the imported time series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1af4791",
      "metadata": {
        "id": "c1af4791"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "df_pcp_1.loc['2020'].cumsum().plot(ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_satellite (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85df75cf",
      "metadata": {
        "id": "85df75cf"
      },
      "source": [
        "#### For Rain Gauge 2\n",
        "\n",
        "Import and preprocess the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "670a4b09",
      "metadata": {
        "id": "670a4b09"
      },
      "outputs": [],
      "source": [
        "folder_pcp_2 = folder+'Rain_gauge_2/'\n",
        "df_pcp_2= pd.read_table(folder_pcp_2+'Rain_gauge_2.csv', sep=',')\n",
        "df_pcp_2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98f70661",
      "metadata": {
        "id": "98f70661"
      },
      "source": [
        "Operaciones para crear un dataframe manejable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2873c748",
      "metadata": {
        "id": "2873c748"
      },
      "outputs": [],
      "source": [
        "df_pcp_2['Date'] = df_pcp_2.Date.apply(lambda x: pd.to_datetime(x,dayfirst=True))\n",
        "df_pcp_2.set_index(df_pcp_2['Date'],inplace=True)\n",
        "df_pcp_2.rename(columns={'Precipitation':'Pluviómetro_2'},inplace=True)\n",
        "df_pcp_2 = df_pcp_2.drop(labels='Date', axis=1)\n",
        "df_pcp_2 = df_pcp_2[~df_pcp_2.index.duplicated(keep='first')]\n",
        "\n",
        "df_pcp_2 = df_pcp_2.sort_index()\n",
        "df_pcp_2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e2dd1e4",
      "metadata": {
        "id": "5e2dd1e4"
      },
      "source": [
        "Plot the year 2020 from the imported series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c1ea79",
      "metadata": {
        "id": "e5c1ea79"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "df_pcp_2.loc['2020'].plot(ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_in situ (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d543a42",
      "metadata": {
        "id": "2d543a42"
      },
      "source": [
        "Plot the accumulated precipitation for the year 2020 from the imported series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed87ddb0",
      "metadata": {
        "id": "ed87ddb0"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "df_pcp_2.loc['2020'].cumsum().plot(ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_satellite (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b5b01be",
      "metadata": {
        "id": "9b5b01be"
      },
      "source": [
        "#### For rain gauge 3\n",
        "\n",
        "Import and preprocess the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fff3454",
      "metadata": {
        "id": "4fff3454"
      },
      "outputs": [],
      "source": [
        "folder_pcp_3 = folder+'Rain_gauge_3/'\n",
        "df_pcp_3= pd.read_table(folder_pcp_3+'Rain_gauge_3.csv', sep=',')\n",
        "df_pcp_3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4364bec1",
      "metadata": {
        "id": "4364bec1"
      },
      "source": [
        "Operations to create a manageable dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc48890",
      "metadata": {
        "id": "1cc48890"
      },
      "outputs": [],
      "source": [
        "df_pcp_3['Fecha'] = df_pcp_3.Fecha.apply(lambda x: pd.to_datetime(x,dayfirst=True))\n",
        "df_pcp_3.set_index(df_pcp_3['Fecha'],inplace=True)\n",
        "df_pcp_3 = df_pcp_3.drop(labels='Fecha', axis=1)\n",
        "df_pcp_3.rename(columns={'Precipitation':'Pluviómetro_3'},inplace=True)\n",
        "df_pcp_3 = df_pcp_3[~df_pcp_3.index.duplicated(keep='first')]\n",
        "\n",
        "df_pcp_3 = df_pcp_3.sort_index()\n",
        "df_pcp_3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77d012d8",
      "metadata": {
        "id": "77d012d8"
      },
      "source": [
        "Plot the precipitation for the year 2020."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df650fea",
      "metadata": {
        "id": "df650fea"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "df_pcp_3.loc['2020'].plot(ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_in situ (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "342ef0a7",
      "metadata": {
        "id": "342ef0a7"
      },
      "source": [
        "Plot the accumulated precipitation for the year 2020."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a757f71",
      "metadata": {
        "id": "6a757f71"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "df_pcp_3.loc['2020'].cumsum().plot(ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_satellite (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bab62747",
      "metadata": {
        "id": "bab62747"
      },
      "source": [
        "#### Compare the in-situ precipitation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b1d1637",
      "metadata": {
        "id": "3b1d1637"
      },
      "source": [
        "Resample the data from the 3 rain gauges to monthly scales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d03db5f",
      "metadata": {
        "id": "1d03db5f"
      },
      "outputs": [],
      "source": [
        "df_pcp_1_monthly = df_pcp_1.resample('M',label='right',closed='right').sum()\n",
        "df_pcp_1_monthly= df_pcp_1_monthly.groupby(df_pcp_1_monthly.index.month).mean()\n",
        "df_pcp_2_monthly = df_pcp_2.resample('M',label='right',closed='right').sum()\n",
        "df_pcp_2_monthly= df_pcp_2_monthly.groupby(df_pcp_2_monthly.index.month).mean()\n",
        "df_pcp_3_monthly = df_pcp_3.resample('M',label='right',closed='right').sum()\n",
        "df_pcp_3_monthly= df_pcp_3_monthly.groupby(df_pcp_3_monthly.index.month).mean()\n",
        "all_pcp_monthly = pd.concat([df_pcp_1_monthly, df_pcp_2_monthly, df_pcp_3_monthly], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9225f235",
      "metadata": {
        "id": "9225f235"
      },
      "source": [
        "Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a27b08b3",
      "metadata": {
        "id": "a27b08b3"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "all_pcp_monthly.plot(kind='bar',ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_in situ (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a67fb1e",
      "metadata": {
        "id": "2a67fb1e"
      },
      "source": [
        "## Import runoff data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d59bddd9",
      "metadata": {
        "id": "d59bddd9"
      },
      "source": [
        "Import and organize runoff data into a manageable dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edac2779",
      "metadata": {
        "scrolled": true,
        "id": "edac2779"
      },
      "outputs": [],
      "source": [
        "folder_runoff = folder+'Runoff_catchment_1/'\n",
        "df_runoff =  pd.read_excel(folder_runoff+'Runoff_catchment_1.xlsx')\n",
        "df_runoff['Fecha'] = df_runoff.Fecha.apply(lambda x: pd.to_datetime(x,dayfirst=True))\n",
        "df_runoff.set_index(df_runoff['Fecha'],inplace=True)\n",
        "df_runoff = df_runoff.drop(labels='Fecha', axis=1)\n",
        "df_runoff"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "456ca367",
      "metadata": {
        "id": "456ca367"
      },
      "source": [
        "Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ff3879b",
      "metadata": {
        "id": "3ff3879b"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "df_runoff.plot(ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Caudal ($m^3/s$)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ada5a4f",
      "metadata": {
        "id": "6ada5a4f"
      },
      "source": [
        "## Combine precipitation (rain gauges + satellite) and flow data for the catchment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37efa7ba",
      "metadata": {
        "id": "37efa7ba"
      },
      "outputs": [],
      "source": [
        "df_pcp_1_daily = df_pcp_1.resample('D',label='right',closed='right').sum()\n",
        "df_pcp_2_daily = df_pcp_2.resample('D',label='right',closed='right').sum()\n",
        "df_pcp_3_daily = df_pcp_3.resample('D',label='right',closed='right').sum()\n",
        "df_runoff_daily = df_runoff.resample('D',label='right',closed='right').mean()\n",
        "all_data_daily = pd.concat([df_pcp_1_daily, df_pcp_2_daily, df_pcp_3_daily, precipitation_satellite, df_runoff_daily], axis=1)\n",
        "all_data_daily"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41b3e6a2",
      "metadata": {
        "id": "41b3e6a2"
      },
      "source": [
        "### Determine periods with concurrent data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a2dd767",
      "metadata": {
        "id": "8a2dd767"
      },
      "outputs": [],
      "source": [
        "concurrent_periods = all_data_daily.dropna().index\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(15, 6))\n",
        "\n",
        "# Loop through columns\n",
        "for i, col in enumerate(all_data_daily.columns):\n",
        "    # Get a boolean mask where data is not NaN for the current column\n",
        "    mask = ~all_data_daily[col].isna()\n",
        "\n",
        "    # Get the indices of True values in the mask\n",
        "    indices = np.where(mask)[0]\n",
        "\n",
        "    # Plot horizontal lines for continuity\n",
        "    ax.hlines(i, indices[0], indices[-1], colors='0.1', linewidth=5, label=col)\n",
        "\n",
        "# Set y-ticks and labels\n",
        "ax.set_yticks(range(len(all_data_daily.columns)))\n",
        "ax.set_yticklabels(all_data_daily.columns)\n",
        "\n",
        "# Set x-axis label\n",
        "ax.set_xlabel('Date')\n",
        "\n",
        "# Set the x-axis ticks to show years\n",
        "years = pd.to_datetime(all_data_daily.index).year\n",
        "unique_years = np.unique(years)\n",
        "ax.set_xticks(np.arange(len(all_data_daily.index), step=365))\n",
        "ax.set_xticklabels(unique_years,rotation=45)\n",
        "\n",
        "# Add legend\n",
        "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=11)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc21eafa",
      "metadata": {
        "id": "fc21eafa"
      },
      "source": [
        "## Split the data into training and test periods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "239e7537",
      "metadata": {
        "id": "239e7537"
      },
      "outputs": [],
      "source": [
        "all_data_daily = all_data_daily[~(all_data_daily.isna().any(axis=1) | (all_data_daily.lt(0).any(axis=1)))]\n",
        "input_data_train = np.array(all_data_daily['2013':'2019'].iloc[:,:-1])\n",
        "input_data_test = np.array(all_data_daily['2020':'2021-06'].iloc[:,:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "423cd98a",
      "metadata": {
        "id": "423cd98a"
      },
      "outputs": [],
      "source": [
        "input_data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6616eafa",
      "metadata": {
        "id": "6616eafa"
      },
      "outputs": [],
      "source": [
        "output_data_train = np.reshape(np.array(all_data_daily['2013':'2019'].iloc[:,-1]),(all_data_daily['2013':'2019'].shape[0],1))\n",
        "output_data_test = np.reshape(np.array(all_data_daily['2020':'2021-06'].iloc[:,-1]),(all_data_daily['2020':'2021-06'].shape[0],1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "707d9bb8",
      "metadata": {
        "id": "707d9bb8"
      },
      "outputs": [],
      "source": [
        "output_data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5501952",
      "metadata": {
        "id": "b5501952"
      },
      "outputs": [],
      "source": [
        "input_data_train_lags, output_data_train_lags= lagged_dataset(input_data_train, 3, output_data_train,15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9c5bd9b",
      "metadata": {
        "id": "c9c5bd9b"
      },
      "outputs": [],
      "source": [
        "input_data_train_lags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec645947",
      "metadata": {
        "id": "ec645947"
      },
      "outputs": [],
      "source": [
        "output_data_train_lags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16a37b0e",
      "metadata": {
        "id": "16a37b0e"
      },
      "outputs": [],
      "source": [
        "input_data_test_lags, output_data_test_lags= lagged_dataset(input_data_test, 3, output_data_test,15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49e74788",
      "metadata": {
        "id": "49e74788"
      },
      "outputs": [],
      "source": [
        "input_data_test_lags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f42cf385",
      "metadata": {
        "id": "f42cf385"
      },
      "outputs": [],
      "source": [
        "output_data_test_lags"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bae96a3d",
      "metadata": {
        "id": "bae96a3d"
      },
      "source": [
        "## Creation and training of a Random Forest model (not forecasting)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2b78f49",
      "metadata": {
        "id": "f2b78f49"
      },
      "source": [
        "### Define model hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad963f0f",
      "metadata": {
        "id": "ad963f0f"
      },
      "outputs": [],
      "source": [
        "min_samples_splt=10\n",
        "min_samples_lf=4\n",
        "max_dpth=350\n",
        "n_trees=600\n",
        "max_ft='sqrt'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dc8e865",
      "metadata": {
        "id": "7dc8e865"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23362103",
      "metadata": {
        "id": "23362103"
      },
      "outputs": [],
      "source": [
        "regr=RandomForestRegressor(bootstrap=True,min_samples_split=min_samples_splt,\n",
        "                               max_depth=max_dpth,max_features=max_ft,\n",
        "                               min_samples_leaf=min_samples_lf,\n",
        "                               n_estimators=n_trees,oob_score=True,n_jobs=-1,\n",
        "                               warm_start=True,random_state=22)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea50d345",
      "metadata": {
        "id": "ea50d345"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ade3adfc",
      "metadata": {
        "id": "ade3adfc"
      },
      "outputs": [],
      "source": [
        "# Correcting the shape of output_data_train_lags\n",
        "regr = regr.fit(input_data_train_lags, output_data_train_lags.ravel())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a6bd88b",
      "metadata": {
        "id": "3a6bd88b"
      },
      "source": [
        "### Generate simulations for the training period"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "403bbb8b",
      "metadata": {
        "id": "403bbb8b"
      },
      "outputs": [],
      "source": [
        "simulations_data_train= regr.predict(input_data_train_lags)\n",
        "simulations_data_train= np.reshape(simulations_data_train, (-1, 1))\n",
        "simulations_data_train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bac04b9",
      "metadata": {
        "id": "7bac04b9"
      },
      "source": [
        "### Generate simulations for the testing period"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edcaf0e3",
      "metadata": {
        "id": "edcaf0e3"
      },
      "outputs": [],
      "source": [
        "#Prediction on unseen data\n",
        "simulations_data_test= regr.predict(input_data_test_lags)\n",
        "simulations_data_test= np.reshape(simulations_data_test, (-1, 1))\n",
        "simulations_data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edf59b53",
      "metadata": {
        "id": "edf59b53"
      },
      "source": [
        "### Model evaluation\n",
        "\n",
        "Calculate the correlation coefficients for the training and testing periods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eee0d34",
      "metadata": {
        "id": "1eee0d34"
      },
      "outputs": [],
      "source": [
        "r2_test=regr.score(input_data_test_lags, output_data_test_lags)\n",
        "r2_train=regr.score(input_data_train_lags, output_data_train_lags)\n",
        "print(r2_train,r2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17bbbcc7",
      "metadata": {
        "id": "17bbbcc7"
      },
      "source": [
        "## Creation and training of a random forest model (forecasting)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4e2609b",
      "metadata": {
        "id": "d4e2609b"
      },
      "source": [
        "### One-day forecasting case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c825a899",
      "metadata": {
        "id": "c825a899"
      },
      "outputs": [],
      "source": [
        "leadtime = 1\n",
        "input_data_train_lags, output_data_train_lags= lagged_dataset_pron(input_data_train, 7, output_data_train,15, lead_time=leadtime)\n",
        "input_data_test_lags, output_data_test_lags= lagged_dataset_pron(input_data_test, 7, output_data_test,15, lead_time=leadtime)\n",
        "min_samples_splt=10\n",
        "min_samples_lf=4\n",
        "max_dpth=350\n",
        "n_trees=600\n",
        "max_ft='sqrt'\n",
        "regr=RandomForestRegressor(bootstrap=True,min_samples_split=min_samples_splt,\n",
        "                               max_depth=max_dpth,max_features=max_ft,\n",
        "                               min_samples_leaf=min_samples_lf,\n",
        "                               n_estimators=n_trees,oob_score=True,n_jobs=-1,\n",
        "                               warm_start=True,random_state=42)\n",
        "regr=regr.fit(input_data_train_lags, output_data_train_lags.ravel())\n",
        "#Prediction on training data\n",
        "simulations_data_train= regr.predict(input_data_train_lags)\n",
        "simulations_data_train= np.reshape(simulations_data_train, (-1, 1))\n",
        "#Prediction on unseen data\n",
        "simulations_data_test= regr.predict(input_data_test_lags)\n",
        "simulations_data_test= np.reshape(simulations_data_test, (-1, 1))\n",
        "r2_test=regr.score(input_data_test_lags, output_data_test_lags)\n",
        "r2_train=regr.score(input_data_train_lags, output_data_train_lags)\n",
        "print(r2_train,r2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4faead0",
      "metadata": {
        "id": "a4faead0"
      },
      "source": [
        "### Forecasts in the testing period"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7f3d4c4",
      "metadata": {
        "id": "a7f3d4c4"
      },
      "outputs": [],
      "source": [
        "simulations_data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5262ad4b",
      "metadata": {
        "id": "5262ad4b"
      },
      "source": [
        "### Evaluation using a combination of efficiency metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9997523",
      "metadata": {
        "id": "e9997523"
      },
      "outputs": [],
      "source": [
        "kge, rmse, pbias , r2 = calculate_hydro_metrics(simulations_data_test, output_data_test_lags)\n",
        "print(f\"RMSE: {rmse[0]:.4f}\")\n",
        "print(f\"PBias: {pbias[0]:.4f}\")\n",
        "print(f\"KGE: {kge[0]:.4f}\")\n",
        "print(f\"R2: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63cdf224",
      "metadata": {
        "id": "63cdf224"
      },
      "source": [
        "### Evaluation through visual inspection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0dd0d7d",
      "metadata": {
        "id": "b0dd0d7d"
      },
      "source": [
        "### One-Day runoff forecasts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b541505d",
      "metadata": {
        "id": "b541505d"
      },
      "outputs": [],
      "source": [
        "simulations_data_test = pd.DataFrame(simulations_data_test, columns=['Forecasts'], index=all_data_daily['2019':'2021-06'].index[-len(simulations_data_test):])\n",
        "simulations_data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a564c026",
      "metadata": {
        "id": "a564c026"
      },
      "source": [
        "### And the runoff observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72705ac0",
      "metadata": {
        "id": "72705ac0"
      },
      "outputs": [],
      "source": [
        "observations_data_test = pd.DataFrame(output_data_test_lags, columns=['Observations'], index=all_data_daily['2019':'2021-06'].index[-len(output_data_test_lags):])\n",
        "observations_data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d72102a",
      "metadata": {
        "id": "4d72102a"
      },
      "source": [
        "### Combine forecasts and observations into a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9c5e0fa",
      "metadata": {
        "id": "a9c5e0fa"
      },
      "outputs": [],
      "source": [
        "testing_period = pd.concat([simulations_data_test, observations_data_test], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5ae60f6",
      "metadata": {
        "id": "e5ae60f6"
      },
      "outputs": [],
      "source": [
        "testing_period"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1bd4499",
      "metadata": {
        "id": "e1bd4499"
      },
      "source": [
        "### Plot (compare) forecasts and observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d7d3511",
      "metadata": {
        "id": "2d7d3511"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calculate mean and percentiles\n",
        "mean_obs = testing_period['Observations'].mean()\n",
        "p05 = testing_period['Observations'].quantile(0.05)\n",
        "p95= testing_period['Observations'].quantile(0.95)\n",
        "\n",
        "# Create the plot\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "# Plot forecasts and observations\n",
        "testing_period['Forecasts'].plot(ax=ax, color='red', marker='o', linestyle='', markersize=2, label='Forecasts')\n",
        "testing_period['Observations'].plot(ax=ax, color='black', linestyle='-', label='Observations')\n",
        "\n",
        "# Add horizontal lines for mean and percentiles\n",
        "ax.axhline(mean_obs, color='blue', linestyle='--', linewidth=1, label=f'Mean ({mean_obs:.2f} $m^3/s$)')\n",
        "ax.axhline(p05, color='green', linestyle=':', linewidth=1, label=f'5th Percentile ({p05:.2f} $m^3/s$)')\n",
        "ax.axhline(p95, color='orange', linestyle=':', linewidth=1, label=f'95th Percentile ({p95:.2f} $m^3/s$)')\n",
        "\n",
        "# Add labels and legend\n",
        "ax.set_ylabel('Runoff ($m^3/s$)')\n",
        "ax.legend(loc='upper right')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86d9500b",
      "metadata": {
        "id": "86d9500b"
      },
      "source": [
        "### Scatter plot of forecasts and observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "592c0d40",
      "metadata": {
        "id": "592c0d40"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import gaussian_kde\n",
        "\n",
        "\n",
        "# Step 1: Clean the data to handle NaN and Inf values\n",
        "testing_period = testing_period.replace([np.inf, -np.inf], np.nan).dropna(subset=['Observations', 'Forecasts'])\n",
        "\n",
        "# Step 2: Scatter plot data\n",
        "x = testing_period['Observations'].values\n",
        "y = testing_period['Forecasts'].values\n",
        "\n",
        "# Step 3: Create the figure and axis\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "\n",
        "# Scatter plot for Observations vs Forecasts\n",
        "sns.scatterplot(x=x, y=y, color='red', marker='o', s=30, label='Forecasts vs Observations', ax=ax)\n",
        "\n",
        "# Step 4: KDE using scipy's gaussian_kde\n",
        "# Create grid for KDE\n",
        "xmin, xmax = x.min(), x.max()\n",
        "ymin, ymax = y.min(), y.max()\n",
        "xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
        "positions = np.vstack([xx.ravel(), yy.ravel()])\n",
        "\n",
        "# Perform KDE\n",
        "kde = gaussian_kde(np.vstack([x, y]))\n",
        "density = np.reshape(kde(positions).T, xx.shape)\n",
        "\n",
        "# Plot KDE contours\n",
        "ax.contour(xx, yy, density, levels=13, cmap='magma')\n",
        "\n",
        "# Step 5: Add bisector line (y = x)\n",
        "min_val = min(xmin, ymin)\n",
        "max_val = max(xmax, ymax)\n",
        "ax.plot([min_val, max_val], [min_val, max_val], color='blue', linestyle='--', label='Bisector Line')\n",
        "\n",
        "# Step 6: Add labels and legend\n",
        "ax.legend(title='Legend Title')\n",
        "ax.set_xlabel('Observations ($m^3/s$)')\n",
        "ax.set_ylabel('Runoff ($m^3/s$)')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28c527a2",
      "metadata": {
        "id": "28c527a2"
      },
      "source": [
        "## Include ENSO data\n",
        "\n",
        "https://psl.noaa.gov/gcos_wgsp/Timeseries/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c2ed620",
      "metadata": {
        "id": "4c2ed620"
      },
      "source": [
        "Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "324f2665",
      "metadata": {
        "id": "324f2665"
      },
      "outputs": [],
      "source": [
        "# Define the path to\n",
        "folder_nino12 = folder+'ENSO/nino12.long.anom.data.xlsx'\n",
        "folder_nino3 = folder+'ENSO/nino3.long.anom.data.xlsx'\n",
        "folder_nino34 = folder+'ENSO/nino34.long.anom.data.xlsx'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7adbb1d",
      "metadata": {
        "id": "c7adbb1d"
      },
      "outputs": [],
      "source": [
        "# Use tabula to extract tables\n",
        "nino12 =  pd.read_excel(folder_nino12)\n",
        "nino3 =  pd.read_excel(folder_nino3)\n",
        "nino34 =  pd.read_excel(folder_nino34)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3bef597",
      "metadata": {
        "id": "a3bef597"
      },
      "outputs": [],
      "source": [
        "# Melt the DataFrame to convert it to long format\n",
        "nino12_long = nino12.melt(id_vars=['Year'], var_name='Month', value_name='Data')\n",
        "# Replace '-99.99' values with NaN\n",
        "nino12_long['Data'] = nino12_long['Data'].replace(-99.99, np.nan)\n",
        "# Convert 'Year' and 'Month' to datetime format\n",
        "nino12_long['Date'] = pd.to_datetime(nino12_long['Year'].astype(str) + '-' + nino12_long['Month'], format='%Y-%B')\n",
        "# Set 'Date' as the index\n",
        "nino12_time_series = nino12_long.set_index('Date')[['Data']]\n",
        "# Display the resulting DataFrame\n",
        "nino12_time_series\n",
        "\n",
        "# Melt the DataFrame to convert it to long format\n",
        "nino3_long = nino3.melt(id_vars=['Year'], var_name='Month', value_name='Data')\n",
        "# Replace '-99.99' values with NaN\n",
        "nino3_long['Data'] = nino3_long['Data'].replace(-99.99, np.nan)\n",
        "# Convert 'Year' and 'Month' to datetime format\n",
        "nino3_long['Date'] = pd.to_datetime(nino3_long['Year'].astype(str) + '-' + nino3_long['Month'], format='%Y-%B')\n",
        "# Set 'Date' as the index\n",
        "nino3_time_series = nino3_long.set_index('Date')[['Data']]\n",
        "# Display the resulting DataFrame\n",
        "nino3_time_series\n",
        "\n",
        "# Melt the DataFrame to convert it to long format\n",
        "nino34_long = nino34.melt(id_vars=['Year'], var_name='Month', value_name='Data')\n",
        "# Replace '-99.99' values with NaN\n",
        "nino34_long['Data'] = nino34_long['Data'].replace(-99.99, np.nan)\n",
        "# Convert 'Year' and 'Month' to datetime format\n",
        "nino34_long['Date'] = pd.to_datetime(nino34_long['Year'].astype(str) + '-' + nino34_long['Month'], format='%Y-%B')\n",
        "# Set 'Date' as the index\n",
        "nino34_time_series = nino34_long.set_index('Date')[['Data']]\n",
        "# Display the resulting DataFrame\n",
        "nino34_time_series"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bca7c59e",
      "metadata": {
        "id": "bca7c59e"
      },
      "source": [
        "### Convert monthly data to daily data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce06c724",
      "metadata": {
        "id": "ce06c724"
      },
      "outputs": [],
      "source": [
        "nino12_df = nino12_time_series.resample('D').ffill()\n",
        "nino3_df = nino3_time_series.resample('D').ffill()\n",
        "nino34_df = nino34_time_series.resample('D').ffill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d1aff46",
      "metadata": {
        "id": "2d1aff46"
      },
      "outputs": [],
      "source": [
        "ENSO_daily = pd.concat([nino12_df,nino3_df,nino34_df], axis=1)\n",
        "ENSO_daily"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0286f86f",
      "metadata": {
        "id": "0286f86f"
      },
      "source": [
        "### Combine all Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "320d4e62",
      "metadata": {
        "id": "320d4e62"
      },
      "outputs": [],
      "source": [
        "all_data_daily_ENSO = pd.concat([all_data_daily, ENSO_daily], axis=1)\n",
        "all_data_daily_ENSO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93021149",
      "metadata": {
        "id": "93021149"
      },
      "outputs": [],
      "source": [
        "all_data_daily_ENSO.loc['2013']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f89c56f8",
      "metadata": {
        "id": "f89c56f8"
      },
      "source": [
        "### Define training and testing periods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83fbce5e",
      "metadata": {
        "id": "83fbce5e"
      },
      "outputs": [],
      "source": [
        "all_data_daily_ENSO = all_data_daily_ENSO[~(all_data_daily_ENSO.isna().any(axis=1))]\n",
        "all_data_daily_ENSO.shape\n",
        "inputs = all_data_daily_ENSO.drop(all_data_daily_ENSO.columns[-4], axis=1)\n",
        "input_data_train = np.array(inputs['2013':'2019'].iloc[:,:-1])\n",
        "input_data_test = np.array(inputs['2020':'2021-06'].iloc[:,:-1])\n",
        "output_data_train = np.reshape(np.array(all_data_daily_ENSO['2013':'2019'].iloc[:,-4]),(all_data_daily_ENSO['2013':'2019'].shape[0],1))\n",
        "output_data_test = np.reshape(np.array(all_data_daily_ENSO['2020':'2021-06'].iloc[:,-4]),(all_data_daily_ENSO['2020':'2021-06'].shape[0],1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e2ea0c0",
      "metadata": {
        "id": "6e2ea0c0"
      },
      "outputs": [],
      "source": [
        "input_data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "738d2ff8",
      "metadata": {
        "id": "738d2ff8"
      },
      "outputs": [],
      "source": [
        "output_data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16484369",
      "metadata": {
        "id": "16484369"
      },
      "source": [
        "## Development of one-day forecasting models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b971e030",
      "metadata": {
        "id": "b971e030"
      },
      "outputs": [],
      "source": [
        "leadtime = 1\n",
        "input_data_train_lags, output_data_train_lags= lagged_dataset_pron(input_data_train, 3, output_data_train,15, lead_time=leadtime)\n",
        "input_data_test_lags, output_data_test_lags= lagged_dataset_pron(input_data_test, 3, output_data_test,15, lead_time=leadtime)\n",
        "min_samples_splt=10\n",
        "min_samples_lf=4\n",
        "max_dpth=350\n",
        "n_trees=600\n",
        "max_ft='sqrt'\n",
        "regr=RandomForestRegressor(bootstrap=True,min_samples_split=min_samples_splt,\n",
        "                               max_depth=max_dpth,max_features=max_ft,\n",
        "                               min_samples_leaf=min_samples_lf,\n",
        "                               n_estimators=n_trees,oob_score=True,n_jobs=-1,\n",
        "                               warm_start=True,random_state=22)\n",
        "regr=regr.fit(input_data_train_lags, output_data_train_lags.ravel())\n",
        "#Prediction on training data\n",
        "simulations_data_train_ENSO= regr.predict(input_data_train_lags)\n",
        "simulations_data_train_ENSO= np.reshape(simulations_data_train_ENSO, (-1, 1))\n",
        "#Prediction on unseen data\n",
        "simulations_data_test_ENSO= regr.predict(input_data_test_lags)\n",
        "simulations_data_test_ENSO= np.reshape(simulations_data_test_ENSO, (-1, 1))\n",
        "r2_test=regr.score(input_data_test_lags, output_data_test_lags)\n",
        "r2_train=regr.score(input_data_train_lags, output_data_train_lags)\n",
        "print(r2_train,r2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d7c6b18",
      "metadata": {
        "id": "4d7c6b18"
      },
      "source": [
        "### Evaluation with efficiency metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54aec896",
      "metadata": {
        "id": "54aec896"
      },
      "outputs": [],
      "source": [
        "kge, rmse, pbias , r2 = calculate_hydro_metrics(simulations_data_test_ENSO, output_data_test_lags)\n",
        "print(f\"RMSE: {rmse[0]:.4f}\")\n",
        "print(f\"PBias: {pbias[0]:.4f}\")\n",
        "print(f\"KGE: {kge[0]:.4f}\")\n",
        "print(f\"R2: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5719eb6",
      "metadata": {
        "id": "e5719eb6"
      },
      "source": [
        "### Visual inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90e9a93c",
      "metadata": {
        "id": "90e9a93c"
      },
      "outputs": [],
      "source": [
        "simulations_data_test_ENSO = pd.DataFrame(simulations_data_test, columns=['Forecasts'], index=all_data_daily['2019':'2021-06'].index[-len(simulations_data_test):])\n",
        "observations_data_test_ENSO = pd.DataFrame(output_data_test_lags, columns=['Observations'], index=all_data_daily['2019':'2021-06'].index[-len(output_data_test_lags):])\n",
        "testing_period_ENSO = pd.concat([simulations_data_test_ENSO, observations_data_test_ENSO], axis=1)\n",
        "\n",
        "\n",
        "# Calculate mean and percentiles for Observations\n",
        "mean_obs = testing_period_ENSO['Observations'].mean()\n",
        "p05 = testing_period_ENSO['Observations'].quantile(0.05)\n",
        "p95 = testing_period_ENSO['Observations'].quantile(0.95)\n",
        "\n",
        "# Create the plot\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "\n",
        "# Plot Forecasts and Observations\n",
        "testing_period_ENSO['Forecasts'].plot(ax=ax, color='red', marker='o', linestyle='', markersize=2, label='Forecasts')\n",
        "testing_period_ENSO['Observations'].plot(ax=ax, color='black', linestyle='-', label='Observations')\n",
        "\n",
        "# Add horizontal lines for mean and percentiles\n",
        "ax.axhline(mean_obs, color='blue', linestyle='--', linewidth=1, label=f'Mean ({mean_obs:.2f} $m^3/s$)')\n",
        "ax.axhline(p05, color='green', linestyle=':', linewidth=1, label=f'5th Percentile ({p05:.2f} $m^3/s$)')\n",
        "ax.axhline(p95, color='orange', linestyle=':', linewidth=1, label=f'95th Percentile ({p95:.2f} $m^3/s$)')\n",
        "\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title', loc='upper right')\n",
        "\n",
        "# Adding a label to the y-axis\n",
        "ax.set_ylabel('Caudal ($m^3/s$)')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afb4e512",
      "metadata": {
        "id": "afb4e512"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 1: Clean the data (replace inf with NaN, drop NaNs)\n",
        "testing_period_ENSO = testing_period_ENSO.replace([np.inf, -np.inf], np.nan).dropna(subset=['Observations', 'Forecasts'])\n",
        "\n",
        "# Step 2: Scatter plot data\n",
        "x = testing_period_ENSO['Observations'].values\n",
        "y = testing_period_ENSO['Forecasts'].values\n",
        "\n",
        "# Create the figure and axis\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "\n",
        "# Scatter plot for Observations vs Forecasts\n",
        "sns.scatterplot(x=x, y=y, color='red', marker='o', s=30, label='Forecasts vs Observations', ax=ax)\n",
        "\n",
        "# Step 3: KDE using scipy's gaussian_kde\n",
        "# Create grid for KDE\n",
        "xmin, xmax = x.min(), x.max()\n",
        "ymin, ymax = y.min(), y.max()\n",
        "xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
        "positions = np.vstack([xx.ravel(), yy.ravel()])\n",
        "\n",
        "# Perform KDE\n",
        "kde = gaussian_kde(np.vstack([x, y]))\n",
        "density = np.reshape(kde(positions).T, xx.shape)\n",
        "\n",
        "# Plot KDE contours\n",
        "ax.contour(xx, yy, density, levels=13, cmap='magma')\n",
        "\n",
        "# Step 4: Add bisector line (y = x)\n",
        "min_val = min(xmin, ymin)\n",
        "max_val = max(xmax, ymax)\n",
        "ax.plot([min_val, max_val], [min_val, max_val], color='blue', linestyle='--', label='Bisector Line')\n",
        "\n",
        "# Step 5: Add labels and legend\n",
        "ax.legend(title='Legend Title')\n",
        "ax.set_xlabel('Observations ($m^3/s$)')\n",
        "ax.set_ylabel('Runoff ($m^3/s$)')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252fee0b",
      "metadata": {
        "id": "252fee0b"
      },
      "source": [
        "## Hyperparameter tuning of the forecasting model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b90ad488",
      "metadata": {
        "id": "b90ad488"
      },
      "source": [
        "### Define hyperparameter search domain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e44fb270",
      "metadata": {
        "id": "e44fb270"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'min_samples_split': [ 10, 20],\n",
        "    'min_samples_leaf': [2, 10],\n",
        "    'max_depth': [100, 300],\n",
        "    'n_estimators': [100, 300],\n",
        "    'max_features': ['sqrt','log2']\n",
        "}\n",
        "\n",
        "# Calculate the total number of combinations\n",
        "total_combinations = len(list(itertools.product(*param_grid.values())))\n",
        "\n",
        "total_combinations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ba6b2a3",
      "metadata": {
        "id": "5ba6b2a3"
      },
      "source": [
        "### Search for the best hyperparameter combination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f2a17f2",
      "metadata": {
        "id": "1f2a17f2"
      },
      "outputs": [],
      "source": [
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=RandomForestRegressor(oob_score=True, n_jobs=-1, warm_start=True),\n",
        "                           param_grid=param_grid, cv=3, n_jobs=-1, scoring='r2')\n",
        "\n",
        "# Fit the GridSearchCV to your data\n",
        "grid_search.fit(input_data_train_lags, output_data_train_lags.ravel())\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c23de2f",
      "metadata": {
        "id": "7c23de2f"
      },
      "source": [
        "### A more rigorous hyperparameterization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43dceff9",
      "metadata": {
        "id": "43dceff9"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'min_samples_split': [5, 10, 20],\n",
        "    'min_samples_leaf': [2, 4, 8],\n",
        "    'max_depth': [100, 200, 350],\n",
        "    'n_estimators': [200, 300, 400, 500, 600],\n",
        "    'max_features': ['auto', 'sqrt','log2']\n",
        "}\n",
        "# Calculate the total number of combinations\n",
        "total_combinations = len(list(itertools.product(*param_grid.values())))\n",
        "\n",
        "total_combinations\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=RandomForestRegressor(oob_score=True, n_jobs=-1, warm_start=True),\n",
        "                           param_grid=param_grid, cv=3, n_jobs=-1, scoring='r2')\n",
        "\n",
        "# Fit the GridSearchCV to your data\n",
        "grid_search.fit(input_data_train_lags, output_data_train_lags.ravel())\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89af12c4",
      "metadata": {
        "id": "89af12c4"
      },
      "outputs": [],
      "source": [
        "best_model\n",
        "simulations_data_train_ENSO= best_model.predict(input_data_train_lags)\n",
        "simulations_data_train_ENSO= np.reshape(simulations_data_train_ENSO, (-1, 1))\n",
        "#Prediction on unseen data\n",
        "simulations_data_test_ENSO= best_model.predict(input_data_test_lags)\n",
        "simulations_data_test_ENSO= np.reshape(simulations_data_test_ENSO, (-1, 1))\n",
        "#Nash_Sutcliffe\n",
        "r2_test=regr.score(input_data_test_lags, output_data_test_lags)\n",
        "r2_train=regr.score(input_data_train_lags, output_data_train_lags)\n",
        "print(r2_train,r2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51b85a22",
      "metadata": {
        "id": "51b85a22"
      },
      "outputs": [],
      "source": [
        "best_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d81fb23d",
      "metadata": {
        "id": "d81fb23d"
      },
      "outputs": [],
      "source": [
        "leadtime = 1\n",
        "input_data_train_lags, output_data_train_lags= lagged_dataset_pron(input_data_train, 3, output_data_train,15, lead_time=leadtime)\n",
        "input_data_test_lags, output_data_test_lags= lagged_dataset_pron(input_data_test, 3, output_data_test,15, lead_time=leadtime)\n",
        "min_samples_splt=10\n",
        "min_samples_lf=2\n",
        "max_dpth=300\n",
        "n_trees=300\n",
        "max_ft='sqrt'\n",
        "regr=RandomForestRegressor(bootstrap=True,min_samples_split=min_samples_splt,\n",
        "                               max_depth=max_dpth,max_features=max_ft,\n",
        "                               min_samples_leaf=min_samples_lf,\n",
        "                               n_estimators=n_trees,oob_score=True,n_jobs=-1,\n",
        "                               warm_start=True,random_state=22)\n",
        "regr=regr.fit(input_data_train_lags, output_data_train_lags.ravel())\n",
        "#Prediction on training data\n",
        "simulations_data_train_ENSO= regr.predict(input_data_train_lags)\n",
        "simulations_data_train_ENSO= np.reshape(simulations_data_train_ENSO, (-1, 1))\n",
        "#Prediction on unseen data\n",
        "simulations_data_test_ENSO= regr.predict(input_data_test_lags)\n",
        "simulations_data_test_ENSO= np.reshape(simulations_data_test_ENSO, (-1, 1))\n",
        "r2_test=regr.score(input_data_test_lags, output_data_test_lags)\n",
        "r2_train=regr.score(input_data_train_lags, output_data_train_lags)\n",
        "print(r2_train,r2_test)\n",
        "kge, rmse, pbias , r2 = calculate_hydro_metrics(simulations_data_test_ENSO, output_data_test_lags)\n",
        "print(f\"RMSE: {rmse[0]:.4f}\")\n",
        "print(f\"PBias: {pbias[0]:.4f}\")\n",
        "print(f\"KGE: {kge[0]:.4f}\")\n",
        "print(f\"R2: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92ca7151",
      "metadata": {
        "id": "92ca7151"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9ed0a22",
      "metadata": {
        "id": "d9ed0a22"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}